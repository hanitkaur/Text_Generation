{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-29T09:26:53.424436Z","iopub.execute_input":"2023-08-29T09:26:53.424739Z","iopub.status.idle":"2023-08-29T09:26:54.693356Z","shell.execute_reply.started":"2023-08-29T09:26:53.424711Z","shell.execute_reply":"2023-08-29T09:26:54.692443Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nietzsche-texts/nietzsche.txt\n/kaggle/input/nyt-comments/CommentsFeb2018.csv\n/kaggle/input/nyt-comments/ArticlesFeb2017.csv\n/kaggle/input/nyt-comments/CommentsApril2018.csv\n/kaggle/input/nyt-comments/ArticlesJan2017.csv\n/kaggle/input/nyt-comments/ArticlesMay2017.csv\n/kaggle/input/nyt-comments/CommentsJan2017.csv\n/kaggle/input/nyt-comments/CommentsMarch2017.csv\n/kaggle/input/nyt-comments/CommentsMay2017.csv\n/kaggle/input/nyt-comments/CommentsMarch2018.csv\n/kaggle/input/nyt-comments/CommentsApril2017.csv\n/kaggle/input/nyt-comments/ArticlesMarch2017.csv\n/kaggle/input/nyt-comments/ArticlesApril2017.csv\n/kaggle/input/nyt-comments/CommentsFeb2017.csv\n/kaggle/input/nyt-comments/ArticlesJan2018.csv\n/kaggle/input/nyt-comments/ArticlesFeb2018.csv\n/kaggle/input/nyt-comments/ArticlesMarch2018.csv\n/kaggle/input/nyt-comments/CommentsJan2018.csv\n/kaggle/input/nyt-comments/ArticlesApril2018.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# CHARACTER LEVEL TEXT GENERATION","metadata":{}},{"cell_type":"markdown","source":"## Loading of Data","metadata":{}},{"cell_type":"code","source":"# Loading the data\nimport keras\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path= keras.utils.get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets.nietzsche.txt')\ntext=open('/kaggle/input/nietzsche-texts/nietzsche.txt').read().lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(' Corpus length:',len(text))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2:- vectorization of data","metadata":{}},{"cell_type":"code","source":"maxlen=60\nsteps=3\nsentences=[]\nnext_chars=[]\nfor i in range(0,len(text)-maxlen,steps):\n    sentences.append(text[i:i+maxlen])\n    next_chars.append(text[i+maxlen])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sentences[0],\" \",next_chars[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sentences[1],\" \",next_chars[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sentences[2],\" \",next_chars[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\" number of sequence:\",len(sentences))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\" number of characters:\",len(next_chars))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars=sorted(list(set(text)))\nprint(chars)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(chars)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_indices=dict((char,chars.index(char)) for char in chars)\nprint(char_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Vectorization....\")\nx=np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\nx.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=np.zeros((len(sentences),len(chars)),dtype=np.bool)\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sentence in enumerate(sentences):\n    for t,char in enumerate(sentence):\n        x[i,t,char_indices[char]]=1\n    y[i,char_indices[char]]=1  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3:- Modelling the data","metadata":{}},{"cell_type":"code","source":"from keras import layers\nmodel=keras.models.Sequential()\nmodel.add(layers.LSTM(128,input_shape=(maxlen,len(chars))))\nmodel.add(layers.Dense(len(chars),activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt=keras.optimizers.RMSprop(lr=0.01)\nmodel.compile(loss='categorical_crossentropy',optimizer=opt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype(\"float64\")\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \nimport sys\nfor i in range(1,30):\n    print('epoch: ',i)\n    model.fit(x,y,batch_size=128,epochs=1)\n   \nfor temp in [0.2,0.5,1.0,1.2]:\n        start_index=random.randint(0,len(text)-60-1)\n        generated_text=text[start_index:start_index+maxlen]\n        print( \"temp- \" ,temp)\n        print(\"sentence:-\",generated_text)\n        generate=\"\"\n        for i in range(400):\n            sampled=np.zeros((1,maxlen,len(chars)))\n            for t,char in enumerate(generated_text):\n                sampled[0,t,char_indices[char]]=1\n\n            preds=model.predict(sampled,verbose=0)[0]\n            #print(preds.shape)\n            next_index = sample(preds, temp)\n            next_char = chars[next_index]\n            #print(next_char)\n            generated_text=generated_text[1:]+ next_char\n            generate=generate+next_char\n        print(\"...Generated: \", generate)\n        print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEXT GENERATION USING LSTM","metadata":{}},{"cell_type":"code","source":"#Loading necessary libraries\n#libraries for data handling\nimport pandas as pd\nimport numpy as np\nimport string, os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T09:27:04.026247Z","iopub.execute_input":"2023-08-29T09:27:04.026665Z","iopub.status.idle":"2023-08-29T09:27:04.032886Z","shell.execute_reply.started":"2023-08-29T09:27:04.026637Z","shell.execute_reply":"2023-08-29T09:27:04.031938Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow\ntensorflow.random.set_seed(2)\nfrom numpy.random import seed\n\nseed(1)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T09:33:34.808412Z","iopub.execute_input":"2023-08-29T09:33:34.809208Z","iopub.status.idle":"2023-08-29T09:33:34.813823Z","shell.execute_reply.started":"2023-08-29T09:33:34.809167Z","shell.execute_reply":"2023-08-29T09:33:34.812952Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras.utils import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nimport keras.utils as ku","metadata":{"execution":{"iopub.status.busy":"2023-08-29T09:31:01.956380Z","iopub.execute_input":"2023-08-29T09:31:01.957197Z","iopub.status.idle":"2023-08-29T09:31:01.962566Z","shell.execute_reply.started":"2023-08-29T09:31:01.957153Z","shell.execute_reply":"2023-08-29T09:31:01.961735Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"curr_dir = '/kaggle/input/nyt-comments/'\nall_headlines = []\nfor filename in os.listdir(curr_dir):\n    print(filename)\n    if 'Articles' in filename:\n        \n        article_df = pd.read_csv(curr_dir + filename)\n        all_headlines.extend(list(article_df.headline.values))\n        break\nall_headlines = [line for line in all_headlines if line!= \"Unknown\"]\nprint(all_headlines[:10])","metadata":{"execution":{"iopub.status.busy":"2023-08-29T09:37:16.660485Z","iopub.execute_input":"2023-08-29T09:37:16.660848Z","iopub.status.idle":"2023-08-29T09:37:16.698757Z","shell.execute_reply.started":"2023-08-29T09:37:16.660819Z","shell.execute_reply":"2023-08-29T09:37:16.697684Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"CommentsFeb2018.csv\nArticlesFeb2017.csv\n['N.F.L. vs. Politics Has Been Battle All Season Long', 'Voice. Vice. Veracity.', 'A Stand-Up’s Downward Slide', 'New York Today: A Groundhog Has Her Day', 'A Swimmer’s Communion With the Ocean', 'Trail Activity', 'Super Bowl', 'Trump’s Mexican Shakedown', 'Pence’s Presidential Pet', 'Fruit of a Poison Tree']\n","output_type":"stream"}]},{"cell_type":"code","source":"len(all_headlines)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:22:23.701885Z","iopub.execute_input":"2023-08-29T10:22:23.702401Z","iopub.status.idle":"2023-08-29T10:22:23.709430Z","shell.execute_reply.started":"2023-08-29T10:22:23.702359Z","shell.execute_reply":"2023-08-29T10:22:23.708390Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"829"},"metadata":{}}]},{"cell_type":"code","source":"def clean_text(txt):\n    txt = \"\".join(t for t in txt if t not in string.punctuation).lower()\n    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n    return txt\ncorpus = [clean_text(x) for x in all_headlines]\nprint(corpus[:10])","metadata":{"execution":{"iopub.status.busy":"2023-08-29T09:38:13.143505Z","iopub.execute_input":"2023-08-29T09:38:13.143915Z","iopub.status.idle":"2023-08-29T09:38:13.159310Z","shell.execute_reply.started":"2023-08-29T09:38:13.143883Z","shell.execute_reply":"2023-08-29T09:38:13.158359Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['nfl vs politics has been battle all season long', 'voice vice veracity', 'a standups downward slide', 'new york today a groundhog has her day', 'a swimmers communion with the ocean', 'trail activity', 'super bowl', 'trumps mexican shakedown', 'pences presidential pet', 'fruit of a poison tree']\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ndef get_sequence_of_tokens(corpus):\n    ## tokenization\n    tokenizer.fit_on_texts(corpus)\n    total_words = len(tokenizer.word_index) + 1\n    print(\"total_words:-\", total_words)\n    ## convert data to a token sequence \n    input_sequences = []\n    for line in corpus:\n        token_list = tokenizer.texts_to_sequences([line])\n        for i in range(1, len(token_list[0])):\n            n_gram_sequence = token_list[0][:i+1]\n        input_sequences.append(n_gram_sequence)\n    return input_sequences, total_words\n\ninp_sequences, total_words = get_sequence_of_tokens(corpus)\nprint(inp_sequences[:10])","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:14:34.389241Z","iopub.execute_input":"2023-08-29T10:14:34.389732Z","iopub.status.idle":"2023-08-29T10:14:34.435389Z","shell.execute_reply.started":"2023-08-29T10:14:34.389694Z","shell.execute_reply":"2023-08-29T10:14:34.434424Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"total_words:- 2288\n[[660, 117, 72, 73, 661, 662, 63, 29, 210], [211, 663, 664], [2, 665, 666, 345], [11, 27, 28, 2, 667, 73, 153, 90], [2, 668, 669, 12, 1, 670], [346, 671], [212, 213], [19, 672, 673], [347, 348, 674], [675, 4, 2, 349, 676]]\n","output_type":"stream"}]},{"cell_type":"code","source":"max_sequence_len = max([len(x) for x in inp_sequences])\nprint(max_sequence_len) ","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:14:53.221211Z","iopub.execute_input":"2023-08-29T10:14:53.221626Z","iopub.status.idle":"2023-08-29T10:14:53.227441Z","shell.execute_reply.started":"2023-08-29T10:14:53.221593Z","shell.execute_reply":"2023-08-29T10:14:53.226520Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"17\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_padded_sequences(input_sequences):\n    max_sequence_len = max([len(x) for x in input_sequences])\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n    \n    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n    #t(predictors,\" \",label)\n    label = ku.to_categorical(label, num_classes=total_words)\n    return predictors, label, max_sequence_len","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:19:00.101383Z","iopub.execute_input":"2023-08-29T10:19:00.101852Z","iopub.status.idle":"2023-08-29T10:19:00.109357Z","shell.execute_reply.started":"2023-08-29T10:19:00.101814Z","shell.execute_reply":"2023-08-29T10:19:00.108086Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:19:04.874612Z","iopub.execute_input":"2023-08-29T10:19:04.875725Z","iopub.status.idle":"2023-08-29T10:19:04.886789Z","shell.execute_reply.started":"2023-08-29T10:19:04.875676Z","shell.execute_reply":"2023-08-29T10:19:04.885613Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"print(predictors.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:19:51.695758Z","iopub.execute_input":"2023-08-29T10:19:51.696768Z","iopub.status.idle":"2023-08-29T10:19:51.701887Z","shell.execute_reply.started":"2023-08-29T10:19:51.696725Z","shell.execute_reply":"2023-08-29T10:19:51.700670Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"(829, 16)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(label.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:19:27.341255Z","iopub.execute_input":"2023-08-29T10:19:27.342248Z","iopub.status.idle":"2023-08-29T10:19:27.346795Z","shell.execute_reply.started":"2023-08-29T10:19:27.342209Z","shell.execute_reply":"2023-08-29T10:19:27.345859Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"(829, 2288)\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_model(max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = Sequential()\n    # ----------Add Input Embedding Layer\n    model.add(Embedding(total_words, 10, input_length=input_len))\n    # ----------Add Hidden Layer 1 - LSTM Layer\n    model.add(LSTM(100))\n    model.add(Dropout(0.1))\n    # ----------Add Output Layer\n    model.add(Dense(total_words, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:22:49.945853Z","iopub.execute_input":"2023-08-29T10:22:49.946882Z","iopub.status.idle":"2023-08-29T10:22:49.953792Z","shell.execute_reply.started":"2023-08-29T10:22:49.946840Z","shell.execute_reply":"2023-08-29T10:22:49.952678Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model = create_model(max_sequence_len, total_words)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:17:04.535531Z","iopub.execute_input":"2023-08-29T10:17:04.536477Z","iopub.status.idle":"2023-08-29T10:17:08.400858Z","shell.execute_reply.started":"2023-08-29T10:17:04.536436Z","shell.execute_reply":"2023-08-29T10:17:08.399868Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 16, 10)            22880     \n                                                                 \n lstm (LSTM)                 (None, 100)               44400     \n                                                                 \n dropout (Dropout)           (None, 100)               0         \n                                                                 \n dense (Dense)               (None, 2288)              231088    \n                                                                 \n=================================================================\nTotal params: 298,368\nTrainable params: 298,368\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(predictors, label, epochs=100, verbose=5)","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:23:25.915030Z","iopub.execute_input":"2023-08-29T10:23:25.916181Z","iopub.status.idle":"2023-08-29T10:24:05.082973Z","shell.execute_reply.started":"2023-08-29T10:23:25.916121Z","shell.execute_reply":"2023-08-29T10:24:05.081791Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Epoch 1/100\nEpoch 2/100\nEpoch 3/100\nEpoch 4/100\nEpoch 5/100\nEpoch 6/100\nEpoch 7/100\nEpoch 8/100\nEpoch 9/100\nEpoch 10/100\nEpoch 11/100\nEpoch 12/100\nEpoch 13/100\nEpoch 14/100\nEpoch 15/100\nEpoch 16/100\nEpoch 17/100\nEpoch 18/100\nEpoch 19/100\nEpoch 20/100\nEpoch 21/100\nEpoch 22/100\nEpoch 23/100\nEpoch 24/100\nEpoch 25/100\nEpoch 26/100\nEpoch 27/100\nEpoch 28/100\nEpoch 29/100\nEpoch 30/100\nEpoch 31/100\nEpoch 32/100\nEpoch 33/100\nEpoch 34/100\nEpoch 35/100\nEpoch 36/100\nEpoch 37/100\nEpoch 38/100\nEpoch 39/100\nEpoch 40/100\nEpoch 41/100\nEpoch 42/100\nEpoch 43/100\nEpoch 44/100\nEpoch 45/100\nEpoch 46/100\nEpoch 47/100\nEpoch 48/100\nEpoch 49/100\nEpoch 50/100\nEpoch 51/100\nEpoch 52/100\nEpoch 53/100\nEpoch 54/100\nEpoch 55/100\nEpoch 56/100\nEpoch 57/100\nEpoch 58/100\nEpoch 59/100\nEpoch 60/100\nEpoch 61/100\nEpoch 62/100\nEpoch 63/100\nEpoch 64/100\nEpoch 65/100\nEpoch 66/100\nEpoch 67/100\nEpoch 68/100\nEpoch 69/100\nEpoch 70/100\nEpoch 71/100\nEpoch 72/100\nEpoch 73/100\nEpoch 74/100\nEpoch 75/100\nEpoch 76/100\nEpoch 77/100\nEpoch 78/100\nEpoch 79/100\nEpoch 80/100\nEpoch 81/100\nEpoch 82/100\nEpoch 83/100\nEpoch 84/100\nEpoch 85/100\nEpoch 86/100\nEpoch 87/100\nEpoch 88/100\nEpoch 89/100\nEpoch 90/100\nEpoch 91/100\nEpoch 92/100\nEpoch 93/100\nEpoch 94/100\nEpoch 95/100\nEpoch 96/100\nEpoch 97/100\nEpoch 98/100\nEpoch 99/100\nEpoch 100/100\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7a19477158e0>"},"metadata":{}}]},{"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_sequence_len):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list],maxlen=max_sequence_len-1, padding='pre')\n        predicted = model.predict(token_list, verbose=0)\n        print(max(predicted[0]))\n        print(next(i for i, x in enumerate(predicted[0]) if x == max(predicted[0])))\n        output_word = \"\"\n        for word,index in tokenizer.word_index.items():\n            if index == next(i for i, x in enumerate(predicted[0]) if x == max(predicted[0])):\n                output_word = word\n                break\n        seed_text += \" \"+output_word\n    return seed_text.title()","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:34:37.185250Z","iopub.execute_input":"2023-08-29T10:34:37.186042Z","iopub.status.idle":"2023-08-29T10:34:37.195405Z","shell.execute_reply.started":"2023-08-29T10:34:37.186003Z","shell.execute_reply":"2023-08-29T10:34:37.194457Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"print (generate_text(\"india and pakistan\", 3, model, max_sequence_len))\nprint (generate_text(\"president trump\", 3, model, max_sequence_len))\nprint (generate_text(\"united states\", 4, model, max_sequence_len))\nprint (generate_text(\"donald trump\", 2, model, max_sequence_len))\nprint (generate_text(\"new york\", 3, model, max_sequence_len))\nprint (generate_text(\"science and technology\", 5, model, max_sequence_len))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-29T10:34:37.587456Z","iopub.execute_input":"2023-08-29T10:34:37.588179Z","iopub.status.idle":"2023-08-29T11:21:54.057497Z","shell.execute_reply.started":"2023-08-29T10:34:37.588141Z","shell.execute_reply":"2023-08-29T11:21:54.056287Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"0.04584018\n834\n0.05971363\n1848\n0.10290712\n62\nIndia And Pakistan Ring Bridges Love\n0.12520811\n859\n0.08023845\n1849\n0.11247846\n90\nPresident Trump Dizziness Intrigue Day\n0.046770703\n504\n0.1766497\n90\n0.036006186\n732\n0.11506696\n90\nUnited States Stories Day Mitch Day\n0.087685525\n504\n0.10985881\n338\nDonald Trump Stories Kind\n0.07144982\n78\n0.16310106\n267\n0.07579539\n136\nNew York Vote Know Night\n0.029884014\n2084\n0.056673773\n2068\n0.051909488\n567\n0.071469516\n133\n0.08774651\n144\nScience And Technology Paris Preening Crisis 2017 Month\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}